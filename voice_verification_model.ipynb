{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8ae9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# OPTIMIZED VOICE RECOGNITION MODEL\n",
    "# Target: 80%+ accuracy with augmented data\n",
    "# ============================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import (accuracy_score, f1_score, classification_report, \n",
    "                             confusion_matrix, log_loss)\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ============================================\n",
    "# STEP 9: COMPREHENSIVE PREDICTION TESTING\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 9: TESTING PREDICTIONS FOR ALL PEOPLE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def authenticate_voice(features_dict, confidence_threshold=0.7):\n",
    "    \"\"\"\n",
    "    Authenticate voice using audio features\n",
    "    \n",
    "    Args:\n",
    "        features_dict: Dictionary of audio features\n",
    "        confidence_threshold: Minimum confidence (0-1)\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with authentication result\n",
    "    \"\"\"\n",
    "    # Extract features in correct order\n",
    "    features = np.array([features_dict[col] for col in feature_columns]).reshape(1, -1)\n",
    "    \n",
    "    # Scale\n",
    "    features_scaled = scaler.transform(features)\n",
    "    \n",
    "    # Predict\n",
    "    pred_class = model.predict(features_scaled)[0]\n",
    "    pred_proba = model.predict_proba(features_scaled)[0]\n",
    "    \n",
    "    # Find the column index\n",
    "    try:\n",
    "        pred_col_index = int(np.where(model.classes_ == pred_class)[0][0])\n",
    "    except:\n",
    "        pred_col_index = int(np.argmax(pred_proba))\n",
    "    \n",
    "    # Decode\n",
    "    combined_label = le_combined.inverse_transform([pred_class])[0]\n",
    "    confidence = float(pred_proba[pred_col_index])\n",
    "    \n",
    "    # Split into person and phrase\n",
    "    person, phrase = combined_label.split('_', 1)\n",
    "    \n",
    "    # Authentication decision\n",
    "    authenticated = confidence >= confidence_threshold\n",
    "    \n",
    "    # Get top 3 predictions\n",
    "    top_cols = np.argsort(pred_proba)[-3:][::-1]\n",
    "    top_3 = []\n",
    "    for col_idx in top_cols:\n",
    "        encoded_label = int(model.classes_[col_idx])\n",
    "        label = le_combined.inverse_transform([encoded_label])[0]\n",
    "        p, ph = label.split('_', 1)\n",
    "        top_3.append({\n",
    "            'person': p,\n",
    "            'phrase': ph,\n",
    "            'confidence': float(pred_proba[col_idx])\n",
    "        })\n",
    "    \n",
    "    return {\n",
    "        'person': person,\n",
    "        'phrase': phrase,\n",
    "        'confidence': confidence,\n",
    "        'authenticated': authenticated,\n",
    "        'combined_label': combined_label,\n",
    "        'top_3_predictions': top_3\n",
    "    }\n",
    "\n",
    "# Test samples from each person\n",
    "print(\"\\nüß™ TESTING PREDICTIONS FOR EACH PERSON:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Get unique people and phrases\n",
    "all_people = sorted(df['person'].unique())\n",
    "all_phrases = sorted(df['phrase'].unique())\n",
    "\n",
    "# Track overall results\n",
    "total_tests = 0\n",
    "correct_person = 0\n",
    "correct_phrase = 0\n",
    "correct_both = 0\n",
    "high_confidence = 0\n",
    "\n",
    "# Test results by person\n",
    "person_results = {person: {'total': 0, 'correct': 0, 'high_conf': 0} for person in all_people}\n",
    "\n",
    "# For each person, test multiple samples\n",
    "for person in all_people:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"TESTING: {person.upper()}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Get all samples for this person\n",
    "    person_df = df[df['person'] == person]\n",
    "    \n",
    "    # Test up to 5 samples per person (or all if less)\n",
    "    n_test = min(5, len(person_df))\n",
    "    test_indices = np.random.choice(person_df.index, size=n_test, replace=False)\n",
    "    \n",
    "    for i, idx in enumerate(test_indices, 1):\n",
    "        sample = df.loc[idx]\n",
    "        features_dict = {col: sample[col] for col in feature_columns}\n",
    "        \n",
    "        print(f\"\\n  Test #{i}:\")\n",
    "        print(f\"  {'‚îÄ'*76}\")\n",
    "        print(f\"  üéØ Ground Truth:\")\n",
    "        print(f\"     Person: {sample['person']:<15s} Phrase: {sample['phrase']}\")\n",
    "        \n",
    "        # Get prediction\n",
    "        result = authenticate_voice(features_dict, confidence_threshold=0.7)\n",
    "        \n",
    "        print(f\"\\n  ü§ñ Prediction:\")\n",
    "        print(f\"     Person: {result['person']:<15s} Phrase: {result['phrase']}\")\n",
    "        print(f\"     Confidence: {result['confidence']*100:.1f}%\")\n",
    "        \n",
    "        # Check correctness\n",
    "        person_match = result['person'] == sample['person']\n",
    "        phrase_match = result['phrase'] == sample['phrase']\n",
    "        both_match = person_match and phrase_match\n",
    "        is_high_conf = result['confidence'] >= 0.7\n",
    "        \n",
    "        # Update counters\n",
    "        total_tests += 1\n",
    "        if person_match:\n",
    "            correct_person += 1\n",
    "        if phrase_match:\n",
    "            correct_phrase += 1\n",
    "        if both_match:\n",
    "            correct_both += 1\n",
    "        if is_high_conf:\n",
    "            high_confidence += 1\n",
    "        \n",
    "        # Update person-specific results\n",
    "        person_results[person]['total'] += 1\n",
    "        if both_match:\n",
    "            person_results[person]['correct'] += 1\n",
    "        if is_high_conf:\n",
    "            person_results[person]['high_conf'] += 1\n",
    "        \n",
    "        # Display verification\n",
    "        print(f\"\\n  ‚úì Verification:\")\n",
    "        print(f\"     Person: {'‚úÖ CORRECT' if person_match else '‚ùå WRONG':<25s} \", end='')\n",
    "        print(f\"Phrase: {'‚úÖ CORRECT' if phrase_match else '‚ùå WRONG'}\")\n",
    "        \n",
    "        # Authentication status\n",
    "        auth_icon = \"‚úÖ\" if result['authenticated'] else \"‚ùå\"\n",
    "        auth_status = \"ACCESS GRANTED\" if result['authenticated'] else \"ACCESS DENIED\"\n",
    "        print(f\"\\n  üîê Authentication: {auth_icon} {auth_status}\")\n",
    "        \n",
    "        # Show top 3 predictions\n",
    "        print(f\"\\n  üìä Top 3 Predictions:\")\n",
    "        for rank, pred in enumerate(result['top_3_predictions'], 1):\n",
    "            marker = \"üëà\" if rank == 1 else \"  \"\n",
    "            print(f\"     {rank}. {pred['person']:<10s} - {pred['phrase']:<25s} ({pred['confidence']*100:5.1f}%) {marker}\")\n",
    "\n",
    "# ============================================\n",
    "# SUMMARY OF ALL TESTS\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"OVERALL TEST SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nüìä AGGREGATE RESULTS:\")\n",
    "print(f\"   Total Tests:           {total_tests}\")\n",
    "print(f\"   {'‚îÄ'*60}\")\n",
    "print(f\"   Person Correct:        {correct_person}/{total_tests} ({correct_person/total_tests*100:.1f}%)\")\n",
    "print(f\"   Phrase Correct:        {correct_phrase}/{total_tests} ({correct_phrase/total_tests*100:.1f}%)\")\n",
    "print(f\"   Both Correct:          {correct_both}/{total_tests} ({correct_both/total_tests*100:.1f}%)\")\n",
    "print(f\"   {'‚îÄ'*60}\")\n",
    "print(f\"   High Confidence (‚â•70%): {high_confidence}/{total_tests} ({high_confidence/total_tests*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nüìä RESULTS BY PERSON:\")\n",
    "print(f\"   {'Person':<15s} {'Tests':<8s} {'Correct':<10s} {'Accuracy':<12s} {'High Conf'}\")\n",
    "print(f\"   {'‚îÄ'*70}\")\n",
    "\n",
    "for person in sorted(person_results.keys()):\n",
    "    stats = person_results[person]\n",
    "    if stats['total'] > 0:\n",
    "        accuracy = stats['correct'] / stats['total'] * 100\n",
    "        conf_pct = stats['high_conf'] / stats['total'] * 100\n",
    "        \n",
    "        # Status icon\n",
    "        if accuracy >= 80:\n",
    "            icon = \"‚úÖ\"\n",
    "        elif accuracy >= 60:\n",
    "            icon = \"‚ö†Ô∏è \"\n",
    "        else:\n",
    "            icon = \"‚ùå\"\n",
    "        \n",
    "        print(f\"   {icon} {person:<12s} {stats['total']:<8d} {stats['correct']:<10d} \"\n",
    "              f\"{accuracy:>5.1f}%       {conf_pct:>5.1f}%\")\n",
    "\n",
    "# Create confusion insights\n",
    "print(f\"\\nüìä CONFUSION ANALYSIS:\")\n",
    "if correct_both < total_tests:\n",
    "    print(f\"   Common Mistakes:\")\n",
    "    \n",
    "    # Track misclassifications\n",
    "    misclass_count = {}\n",
    "    \n",
    "    for person in all_people:\n",
    "        person_df = df[df['person'] == person]\n",
    "        for idx in person_df.index[:3]:  # Check first 3 of each\n",
    "            sample = df.loc[idx]\n",
    "            features_dict = {col: sample[col] for col in feature_columns}\n",
    "            result = authenticate_voice(features_dict, confidence_threshold=0.7)\n",
    "            \n",
    "            if result['person'] != sample['person'] or result['phrase'] != sample['phrase']:\n",
    "                true_label = f\"{sample['person']}_{sample['phrase']}\"\n",
    "                pred_label = f\"{result['person']}_{result['phrase']}\"\n",
    "                key = f\"{true_label} ‚Üí {pred_label}\"\n",
    "                misclass_count[key] = misclass_count.get(key, 0) + 1\n",
    "    \n",
    "    # Show top 5 most common confusions\n",
    "    if misclass_count:\n",
    "        sorted_confusions = sorted(misclass_count.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "        for confusion, count in sorted_confusions:\n",
    "            print(f\"      ‚Ä¢ {confusion}: {count}x\")\n",
    "    else:\n",
    "        print(f\"      ‚úÖ No consistent confusion patterns detected!\")\n",
    "else:\n",
    "    print(f\"   ‚úÖ Perfect predictions - no confusion!\")\n",
    "\n",
    "# Performance interpretation\n",
    "print(f\"\\nüí° INTERPRETATION:\")\n",
    "both_correct_pct = correct_both / total_tests * 100\n",
    "\n",
    "if both_correct_pct >= 90:\n",
    "    print(f\"   ‚úÖ EXCELLENT! Model is highly reliable ({both_correct_pct:.1f}%)\")\n",
    "    print(f\"      Ready for production deployment!\")\n",
    "elif both_correct_pct >= 80:\n",
    "    print(f\"   ‚úÖ GOOD! Model meets target ({both_correct_pct:.1f}%)\")\n",
    "    print(f\"      Suitable for most authentication scenarios.\")\n",
    "elif both_correct_pct >= 70:\n",
    "    print(f\"   ‚ö†Ô∏è  ACCEPTABLE ({both_correct_pct:.1f}%)\")\n",
    "    print(f\"      May need additional training data for critical applications.\")\n",
    "else:\n",
    "    print(f\"   ‚ùå NEEDS IMPROVEMENT ({both_correct_pct:.1f}%)\")\n",
    "    print(f\"      Recommendations:\")\n",
    "    print(f\"      - Collect more training samples per person\")\n",
    "    print(f\"      - Balance dataset across all phrases\")\n",
    "    print(f\"      - Consider ensemble methods\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"OPTIMIZED VOICE RECOGNITION MODEL\")\n",
    "print(\"Target: 80%+ accuracy with 76 samples\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ============================================\n",
    "# STEP 1: LOAD DATA\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 1: LOADING DATA\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "CSV_FILE = \"features_audio/audio_features.csv\"\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(CSV_FILE)\n",
    "    print(f\"‚úÖ Loaded: {CSV_FILE}\")\n",
    "    print(f\"   Total samples: {len(df)}\")\n",
    "except:\n",
    "    print(f\"‚ùå ERROR: Could not load {CSV_FILE}\")\n",
    "    exit(1)\n",
    "\n",
    "# Remove leakage columns\n",
    "LEAKAGE_COLS = ['audio_path', 'audio_name', 'audio_id', 'augmentation', 'is_augmented']\n",
    "for col in LEAKAGE_COLS:\n",
    "    if col in df.columns:\n",
    "        df = df.drop(columns=[col])\n",
    "\n",
    "print(f\"\\nüìä DATASET:\")\n",
    "print(f\"   People: {len(df['person'].unique())}\")\n",
    "print(f\"   Phrases: {len(df['phrase'].unique())}\")\n",
    "\n",
    "for person in sorted(df['person'].unique()):\n",
    "    count = (df['person'] == person).sum()\n",
    "    print(f\"   {person}: {count} samples\")\n",
    "\n",
    "# ============================================\n",
    "# STEP 2: SMART FEATURE SELECTION\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 2: INTELLIGENT FEATURE SELECTION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Get only numeric features\n",
    "metadata_cols = ['person', 'phrase']\n",
    "all_cols = df.columns.tolist()\n",
    "\n",
    "# Select numeric columns only\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "feature_columns = [c for c in numeric_cols if c not in metadata_cols]\n",
    "\n",
    "print(f\"\\nüîç Initial features: {len(feature_columns)}\")\n",
    "\n",
    "# Remove low-variance features\n",
    "X_temp = df[feature_columns].values\n",
    "feature_variances = np.var(X_temp, axis=0)\n",
    "good_features = [feature_columns[i] for i in range(len(feature_columns)) \n",
    "                 if feature_variances[i] > 0.01]\n",
    "\n",
    "print(f\"   After variance filter: {len(good_features)}\")\n",
    "\n",
    "# Create combined labels for feature selection\n",
    "df['combined_label'] = df['person'] + '_' + df['phrase']\n",
    "le_temp = LabelEncoder()\n",
    "y_temp = le_temp.fit_transform(df['combined_label'])\n",
    "\n",
    "# Select top K features using ANOVA F-test\n",
    "k = min(50, len(good_features))  # Select top 50 or all if less\n",
    "selector = SelectKBest(f_classif, k=k)\n",
    "X_selected = selector.fit_transform(df[good_features], y_temp)\n",
    "selected_mask = selector.get_support()\n",
    "feature_columns = [good_features[i] for i, selected in enumerate(selected_mask) if selected]\n",
    "\n",
    "print(f\"   After statistical selection: {len(feature_columns)}\")\n",
    "print(f\"\\n‚úÖ Using {len(feature_columns)} most discriminative features\")\n",
    "\n",
    "# Feature matrix\n",
    "X = df[feature_columns].values.astype(float)\n",
    "\n",
    "# ============================================\n",
    "# STEP 3: CREATE LABELS\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 3: CREATING LABELS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "y_combined = df['combined_label'].values\n",
    "le_combined = LabelEncoder()\n",
    "y_encoded = le_combined.fit_transform(y_combined)\n",
    "\n",
    "print(f\"\\nüéØ Classes: {len(le_combined.classes_)}\")\n",
    "print(f\"   Samples per class: {len(df) // len(le_combined.classes_):.1f} average\")\n",
    "\n",
    "# Check class balance\n",
    "class_counts = pd.Series(y_combined).value_counts()\n",
    "if class_counts.min() < 2:\n",
    "    print(f\"\\n‚ö†Ô∏è  WARNING: Some classes have < 2 samples!\")\n",
    "    print(\"   Consider removing rare classes or collecting more data\")\n",
    "\n",
    "le_person = LabelEncoder()\n",
    "le_person.fit(df['person'].unique())\n",
    "\n",
    "le_phrase = LabelEncoder()\n",
    "le_phrase.fit(df['phrase'].unique())\n",
    "\n",
    "# ============================================\n",
    "# STEP 4: TRAIN/TEST SPLIT\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 4: SMART DATA SPLITTING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Use stratified split to maintain class balance\n",
    "try:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y_encoded,\n",
    "        test_size=0.25,  # Smaller test set = more training data\n",
    "        random_state=42,\n",
    "        stratify=y_encoded\n",
    "    )\n",
    "    print(\"   ‚úÖ Using stratified split\")\n",
    "except:\n",
    "    # Fallback if stratification fails\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y_encoded,\n",
    "        test_size=0.25,\n",
    "        random_state=42\n",
    "    )\n",
    "    print(\"   ‚ö†Ô∏è  Using random split (stratification failed)\")\n",
    "\n",
    "print(f\"\\nüìä Split:\")\n",
    "print(f\"   Training: {len(X_train)} samples ({len(X_train)/len(X)*100:.1f}%)\")\n",
    "print(f\"   Testing: {len(X_test)} samples ({len(X_test)/len(X)*100:.1f}%)\")\n",
    "\n",
    "# Scale features (CRITICAL!)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"‚úÖ Features scaled\")\n",
    "\n",
    "# ============================================\n",
    "# STEP 5: TRAIN OPTIMIZED MODEL\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 5: TRAINING OPTIMIZED MODEL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nüéØ Strategy for 76 samples with 33 classes:\")\n",
    "print(\"   ‚úì Feature selection (reduced dimensionality)\")\n",
    "print(\"   ‚úì Gradient Boosting (better for imbalanced data)\")\n",
    "print(\"   ‚úì Careful hyperparameters to prevent overfitting)\")\n",
    "print(\"   ‚úì Stratified cross-validation\")\n",
    "\n",
    "# Use Gradient Boosting - often better than RF for small datasets\n",
    "model = GradientBoostingClassifier(\n",
    "    n_estimators=150,      # Moderate number of boosting stages\n",
    "    learning_rate=0.05,    # Slow learning = better generalization\n",
    "    max_depth=4,           # Shallow trees = less overfitting\n",
    "    min_samples_split=4,   # Require multiple samples to split\n",
    "    min_samples_leaf=2,    # Require multiple samples in leaves\n",
    "    subsample=0.8,         # Use 80% of samples per tree\n",
    "    max_features='sqrt',   # Use subset of features\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\nüîß Model: Gradient Boosting\")\n",
    "print(f\"   Estimators: {model.n_estimators}\")\n",
    "print(f\"   Learning rate: {model.learning_rate}\")\n",
    "print(f\"   Max depth: {model.max_depth}\")\n",
    "\n",
    "print(f\"\\n‚è≥ Training...\")\n",
    "model.fit(X_train_scaled, y_train)\n",
    "print(\"‚úÖ Training complete!\")\n",
    "\n",
    "# ============================================\n",
    "# STEP 6: COMPREHENSIVE EVALUATION\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 6: MODEL EVALUATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Predictions\n",
    "y_train_pred = model.predict(X_train_scaled)\n",
    "y_test_pred = model.predict(X_test_scaled)\n",
    "y_test_proba = model.predict_proba(X_test_scaled)\n",
    "\n",
    "# Metrics\n",
    "train_acc = accuracy_score(y_train, y_train_pred)\n",
    "test_acc = accuracy_score(y_test, y_test_pred)\n",
    "f1 = f1_score(y_test, y_test_pred, average='weighted', zero_division=0)\n",
    "\n",
    "# Log loss (safe)\n",
    "try:\n",
    "    mask = np.isin(y_test, model.classes_)\n",
    "    if mask.sum() > 0:\n",
    "        loss = log_loss(y_test[mask], y_test_proba[mask])\n",
    "    else:\n",
    "        loss = 0.0\n",
    "except:\n",
    "    loss = 0.0\n",
    "\n",
    "overfitting_gap = train_acc - test_acc\n",
    "\n",
    "# Cross-validation\n",
    "try:\n",
    "    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=cv, scoring='accuracy')\n",
    "    cv_mean = cv_scores.mean()\n",
    "    cv_std = cv_scores.std()\n",
    "except:\n",
    "    cv_mean = test_acc\n",
    "    cv_std = 0.0\n",
    "\n",
    "print(f\"\\nüìä PERFORMANCE METRICS:\")\n",
    "print(f\"   {'‚îÄ'*60}\")\n",
    "print(f\"   Training Accuracy:     {train_acc*100:6.2f}%\")\n",
    "print(f\"   Testing Accuracy:      {test_acc*100:6.2f}%\")\n",
    "print(f\"   Cross-Val Accuracy:    {cv_mean*100:6.2f}% (¬±{cv_std*100:.2f}%)\")\n",
    "print(f\"   {'‚îÄ'*60}\")\n",
    "print(f\"   F1-Score (weighted):   {f1:6.4f}\")\n",
    "print(f\"   Log Loss:              {loss:6.4f}\")\n",
    "print(f\"   Overfitting Gap:       {overfitting_gap*100:6.2f}%\")\n",
    "print(f\"   {'‚îÄ'*60}\")\n",
    "\n",
    "# Interpretation\n",
    "print(f\"\\nüí° RESULT:\")\n",
    "if test_acc >= 0.80:\n",
    "    print(f\"   ‚úÖ EXCELLENT! Target achieved: {test_acc*100:.1f}% ‚â• 80%\")\n",
    "elif test_acc >= 0.70:\n",
    "    print(f\"   ‚úÖ GOOD! Close to target: {test_acc*100:.1f}%\")\n",
    "elif test_acc >= 0.60:\n",
    "    print(f\"   ‚ö†Ô∏è  ACCEPTABLE: {test_acc*100:.1f}% (dataset is challenging)\")\n",
    "else:\n",
    "    print(f\"   ‚ùå NEEDS IMPROVEMENT: {test_acc*100:.1f}%\")\n",
    "\n",
    "if overfitting_gap <= 0.10:\n",
    "    print(f\"   ‚úÖ Good generalization (gap: {overfitting_gap*100:.1f}%)\")\n",
    "else:\n",
    "    print(f\"   ‚ö†Ô∏è  Some overfitting (gap: {overfitting_gap*100:.1f}%)\")\n",
    "\n",
    "# Per-class performance\n",
    "print(f\"\\nüìã Per-Class Accuracy:\")\n",
    "per_class_acc = []\n",
    "for i in range(len(le_combined.classes_)):\n",
    "    mask = (y_test == i)\n",
    "    if mask.sum() > 0:\n",
    "        acc = (y_test_pred[mask] == y_test[mask]).mean()\n",
    "        per_class_acc.append(acc)\n",
    "        if acc >= 0.8:\n",
    "            status = \"‚úÖ\"\n",
    "        elif acc >= 0.5:\n",
    "            status = \"‚ö†Ô∏è \"\n",
    "        else:\n",
    "            status = \"‚ùå\"\n",
    "        class_name = le_combined.classes_[i]\n",
    "        print(f\"   {status} {class_name:30s} {acc*100:5.1f}% ({mask.sum()} samples)\")\n",
    "    else:\n",
    "        per_class_acc.append(0.0)\n",
    "\n",
    "# ============================================\n",
    "# STEP 7: VISUALIZATION\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 7: CREATING VISUALIZATIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "fig = plt.figure(figsize=(20, 12))\n",
    "plt.suptitle(f'Optimized Voice Model - {len(df)} samples, {len(le_combined.classes_)} classes', \n",
    "             fontsize=14, fontweight='bold')\n",
    "\n",
    "# 1. Confusion Matrix\n",
    "plt.subplot(2, 3, 1)\n",
    "try:\n",
    "    unique_in_test = sorted(list(set(y_test)))\n",
    "    cm = confusion_matrix(y_test, y_test_pred, labels=unique_in_test)\n",
    "    labels_display = [le_combined.classes_[i] for i in unique_in_test]\n",
    "    \n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=labels_display,\n",
    "                yticklabels=labels_display,\n",
    "                cbar_kws={'label': 'Count'})\n",
    "    plt.title('Confusion Matrix\\n(Test Set)', fontweight='bold', fontsize=12)\n",
    "    plt.ylabel('True', fontweight='bold')\n",
    "    plt.xlabel('Predicted', fontweight='bold')\n",
    "    plt.xticks(rotation=45, ha='right', fontsize=7)\n",
    "    plt.yticks(rotation=0, fontsize=7)\n",
    "except Exception as e:\n",
    "    plt.text(0.5, 0.5, f'Confusion Matrix\\nError: {str(e)[:50]}', \n",
    "             ha='center', va='center', fontsize=10)\n",
    "    plt.axis('off')\n",
    "\n",
    "# 2. Accuracy Comparison\n",
    "plt.subplot(2, 3, 2)\n",
    "metrics = ['Training', 'Testing', 'Cross-Val']\n",
    "scores = [train_acc*100, test_acc*100, cv_mean*100]\n",
    "colors = ['#3498db', '#e74c3c', '#2ecc71']\n",
    "bars = plt.bar(metrics, scores, color=colors, alpha=0.85, edgecolor='black', linewidth=2)\n",
    "plt.ylabel('Accuracy (%)', fontweight='bold', fontsize=12)\n",
    "plt.title('Model Performance', fontweight='bold', fontsize=12)\n",
    "plt.ylim(0, 105)\n",
    "plt.axhline(y=80, color='red', linestyle='--', linewidth=2, label='Target: 80%', alpha=0.7)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.legend(fontsize=10)\n",
    "\n",
    "for bar, score in zip(bars, scores):\n",
    "    h = bar.get_height()\n",
    "    color = 'green' if score >= 80 else 'orange' if score >= 70 else 'red'\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., h + 2,\n",
    "            f'{score:.1f}%', ha='center', fontweight='bold', fontsize=13, color=color)\n",
    "\n",
    "# 3. Metrics Summary\n",
    "plt.subplot(2, 3, 3)\n",
    "status_color = '#90EE90' if test_acc >= 0.8 else '#FFE4B5' if test_acc >= 0.7 else '#FFB6C1'\n",
    "summary_text = f\"\"\"\n",
    "PERFORMANCE SUMMARY\n",
    "\n",
    "‚úì Training:    {train_acc*100:.1f}%\n",
    "‚úì Testing:     {test_acc*100:.1f}%\n",
    "‚úì Cross-Val:   {cv_mean*100:.1f}% (¬±{cv_std*100:.1f}%)\n",
    "\n",
    "‚úì F1-Score:    {f1:.3f}\n",
    "‚úì Log Loss:    {loss:.3f}\n",
    "‚úì Overfitting: {overfitting_gap*100:.1f}%\n",
    "\n",
    "Dataset: {len(df)} samples\n",
    "Classes: {len(le_combined.classes_)}\n",
    "Features: {len(feature_columns)}\n",
    "\n",
    "{'‚úÖ TARGET ACHIEVED!' if test_acc >= 0.8 else '‚ö†Ô∏è CLOSE TO TARGET' if test_acc >= 0.7 else '‚ùå NEEDS IMPROVEMENT'}\n",
    "\"\"\"\n",
    "plt.text(0.1, 0.5, summary_text, ha='left', va='center', fontsize=11,\n",
    "         family='monospace', fontweight='bold',\n",
    "         bbox=dict(boxstyle='round', facecolor=status_color, alpha=0.7, edgecolor='black', linewidth=2))\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0, 1)\n",
    "plt.axis('off')\n",
    "\n",
    "# 4. Feature Importance\n",
    "plt.subplot(2, 3, 4)\n",
    "if hasattr(model, 'feature_importances_'):\n",
    "    importances = model.feature_importances_\n",
    "    n_show = min(20, len(importances))\n",
    "    top_indices = np.argsort(importances)[-n_show:]\n",
    "    \n",
    "    plt.barh(range(n_show), importances[top_indices], \n",
    "             color='steelblue', alpha=0.8, edgecolor='black', linewidth=0.5)\n",
    "    plt.yticks(range(n_show), [feature_columns[i][:25] for i in top_indices], fontsize=8)\n",
    "    plt.xlabel('Importance', fontweight='bold', fontsize=11)\n",
    "    plt.title(f'Top {n_show} Features', fontweight='bold', fontsize=12)\n",
    "    plt.grid(axis='x', alpha=0.3)\n",
    "else:\n",
    "    plt.text(0.5, 0.5, 'Feature Importance\\nNot Available', ha='center', va='center', fontsize=12)\n",
    "    plt.axis('off')\n",
    "\n",
    "# 5. Per-Class Performance\n",
    "plt.subplot(2, 3, 5)\n",
    "if len(per_class_acc) > 0:\n",
    "    # Only show classes that appear in test set\n",
    "    classes_with_test = [(i, le_combined.classes_[i], per_class_acc[i]) \n",
    "                         for i in range(len(per_class_acc)) if per_class_acc[i] > 0]\n",
    "    \n",
    "    if classes_with_test:\n",
    "        indices, labels, accs = zip(*classes_with_test)\n",
    "        n_show = min(15, len(classes_with_test))\n",
    "        \n",
    "        # Show top N by accuracy\n",
    "        sorted_items = sorted(zip(labels, accs), key=lambda x: x[1], reverse=True)[:n_show]\n",
    "        labels_show, accs_show = zip(*sorted_items)\n",
    "        \n",
    "        colors_class = ['#2ecc71' if a >= 0.8 else '#f39c12' if a >= 0.6 else '#e74c3c' \n",
    "                        for a in accs_show]\n",
    "        \n",
    "        y_pos = np.arange(len(labels_show))\n",
    "        plt.barh(y_pos, [a*100 for a in accs_show], color=colors_class, alpha=0.85, edgecolor='black', linewidth=0.5)\n",
    "        plt.yticks(y_pos, [l[:25] for l in labels_show], fontsize=8)\n",
    "        plt.xlabel('Accuracy (%)', fontweight='bold', fontsize=11)\n",
    "        plt.title(f'Top {n_show} Class Accuracy', fontweight='bold', fontsize=12)\n",
    "        plt.xlim(0, 105)\n",
    "        plt.grid(axis='x', alpha=0.3)\n",
    "        \n",
    "        for i, acc in enumerate(accs_show):\n",
    "            plt.text(acc*100 + 2, i, f'{acc*100:.0f}%', va='center', fontweight='bold', fontsize=9)\n",
    "\n",
    "# 6. Sample Distribution\n",
    "plt.subplot(2, 3, 6)\n",
    "people_counts = df['person'].value_counts()\n",
    "x = np.arange(len(people_counts))\n",
    "bars = plt.bar(x, people_counts.values, color='#3498db', alpha=0.8, edgecolor='black', linewidth=2)\n",
    "plt.xticks(x, people_counts.index, rotation=0, fontsize=11, fontweight='bold')\n",
    "plt.ylabel('Sample Count', fontweight='bold', fontsize=12)\n",
    "plt.title('Dataset Distribution', fontweight='bold', fontsize=12)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "for i, (bar, count) in enumerate(zip(bars, people_counts.values)):\n",
    "    plt.text(i, count + 1, str(count), ha='center', fontweight='bold', fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('voice_model_optimized.png', dpi=300, bbox_inches='tight')\n",
    "print(\"‚úÖ Visualization saved: voice_model_optimized.png\")\n",
    "plt.show()\n",
    "\n",
    "# ============================================\n",
    "# STEP 8: SAVE MODEL\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 8: SAVING MODEL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "Path(\"voice_models\").mkdir(exist_ok=True)\n",
    "\n",
    "complete_model = {\n",
    "    'model': model,\n",
    "    'model_name': 'Gradient Boosting (Optimized)',\n",
    "    'scaler': scaler,\n",
    "    'le_combined': le_combined,\n",
    "    'le_person': le_person,\n",
    "    'le_phrase': le_phrase,\n",
    "    'feature_columns': feature_columns,\n",
    "    'performance': {\n",
    "        'train_accuracy': float(train_acc),\n",
    "        'test_accuracy': float(test_acc),\n",
    "        'cv_accuracy': float(cv_mean),\n",
    "        'cv_std': float(cv_std),\n",
    "        'f1_score': float(f1),\n",
    "        'log_loss': float(loss),\n",
    "        'overfitting_gap': float(overfitting_gap)\n",
    "    },\n",
    "    'metadata': {\n",
    "        'n_samples': len(df),\n",
    "        'n_features': len(feature_columns),\n",
    "        'n_classes': len(le_combined.classes_),\n",
    "        'people': list(df['person'].unique()),\n",
    "        'phrases': list(df['phrase'].unique())\n",
    "    }\n",
    "}\n",
    "\n",
    "model_path = 'voice_models/voice_recognition_optimized.pkl',\n",
    "joblib.dump(complete_model, model_path)\n",
    "joblib.dump(scaler, 'voice_models/scaler_voice.pkl')\n",
    "joblib.dump(le_combined, 'voice_models/label_encoder_voice.pkl')\n",
    "\n",
    "print(f\"‚úÖ Model saved: {model_path}\")\n",
    "print(\"‚úÖ Scaler saved: voice_models/scaler_voice.pkl\")\n",
    "print(\"‚úÖ Label encoder saved: voice_models/label_encoder_voice.pkl\")\n",
    "\n",
    "# Save summary\n",
    "summary_df = pd.DataFrame({\n",
    "    'Metric': ['Training Accuracy', 'Testing Accuracy', 'Cross-Val Accuracy', \n",
    "               'F1-Score', 'Log Loss', 'Overfitting Gap', 'Target Status'],\n",
    "    'Value': [f'{train_acc*100:.2f}%', f'{test_acc*100:.2f}%', f'{cv_mean*100:.2f}%',\n",
    "              f'{f1:.4f}', f'{loss:.4f}', f'{overfitting_gap*100:.2f}%',\n",
    "              'ACHIEVED ‚úÖ' if test_acc >= 0.8 else 'CLOSE ‚ö†Ô∏è' if test_acc >= 0.7 else 'NOT MET ‚ùå']\n",
    "})\n",
    "\n",
    "summary_df.to_csv('voice_models/model_summary_optimized.csv', index=False)\n",
    "print(f\"‚úÖ Summary saved: voice_models/model_summary_optimized.csv\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"OPTIMIZATION COMPLETE!\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\"\"\n",
    "FINAL RESULTS:\n",
    "\n",
    "üìä Accuracy:        {test_acc*100:.1f}%\n",
    "üéØ Target (80%):    {'‚úÖ ACHIEVED!' if test_acc >= 0.8 else '‚ö†Ô∏è CLOSE' if test_acc >= 0.7 else '‚ùå Not met'}\n",
    "üí™ F1-Score:        {f1:.3f}\n",
    "üî• Overfitting:     {overfitting_gap*100:.1f}% ({'Good' if overfitting_gap <= 0.1 else 'High'})\n",
    "\n",
    "Dataset:            {len(df)} samples\n",
    "Classes:            {len(le_combined.classes_)}\n",
    "Features Used:      {len(feature_columns)}\n",
    "\n",
    "{'‚úÖ Model is READY for deployment!' if test_acc >= 0.75 else '‚ö†Ô∏è aConsider collecting more training data'}\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
