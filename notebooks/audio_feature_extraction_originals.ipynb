{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16892cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and helper functions (enhanced extractor)\n",
    "import os\n",
    "from pathlib import Path\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def extract_basic_features(path, sr=22050):\n",
    "    \"\"\"Extract extended audio features for a single file.\"\"\"\n",
    "    try:\n",
    "        y, sr = librosa.load(path, sr=sr)\n",
    "    except Exception as e:\n",
    "        print('Failed to load', path, e)\n",
    "        return None\n",
    "    feats = {}\n",
    "    # basic metadata\n",
    "    try:\n",
    "        duration = float(librosa.get_duration(y=y, sr=sr))\n",
    "    except Exception:\n",
    "        duration = 0.0\n",
    "    feats['duration'] = duration\n",
    "    feats['sample_rate'] = float(sr)\n",
    "    # RMS energy (mean/std)\n",
    "    try:\n",
    "        rms = librosa.feature.rms(y=y)[0]\n",
    "        feats['rms_mean'] = float(np.mean(rms))\n",
    "        feats['rms_std'] = float(np.std(rms))\n",
    "    except Exception:\n",
    "        feats['rms_mean'] = 0.0\n",
    "        feats['rms_std'] = 0.0\n",
    "    # Zero-crossing rate (mean/std)\n",
    "    try:\n",
    "        zcr = librosa.feature.zero_crossing_rate(y)[0]\n",
    "        feats['zcr_mean'] = float(np.mean(zcr))\n",
    "        feats['zcr_std'] = float(np.std(zcr))\n",
    "    except Exception:\n",
    "        feats['zcr_mean'] = 0.0\n",
    "        feats['zcr_std'] = 0.0\n",
    "    # Tempo\n",
    "    try:\n",
    "        onset_env = librosa.onset.onset_strength(y=y, sr=sr)\n",
    "        tempo = librosa.beat.tempo(onset_envelope=onset_env, sr=sr)\n",
    "        feats['tempo'] = float(tempo[0]) if len(tempo) else 0.0\n",
    "    except Exception:\n",
    "        feats['tempo'] = 0.0\n",
    "    # Spectral centroid / rolloff / bandwidth (mean/std)\n",
    "    try:\n",
    "        sc = librosa.feature.spectral_centroid(y=y, sr=sr)[0]\n",
    "        feats['spectral_centroid_mean'] = float(np.mean(sc))\n",
    "        feats['spectral_centroid_std'] = float(np.std(sc))\n",
    "    except Exception:\n",
    "        feats['spectral_centroid_mean'] = 0.0\n",
    "        feats['spectral_centroid_std'] = 0.0\n",
    "    try:\n",
    "        roll = librosa.feature.spectral_rolloff(y=y, sr=sr)[0]\n",
    "        feats['spectral_rolloff_mean'] = float(np.mean(roll))\n",
    "        feats['spectral_rolloff_std'] = float(np.std(roll))\n",
    "    except Exception:\n",
    "        feats['spectral_rolloff_mean'] = 0.0\n",
    "        feats['spectral_rolloff_std'] = 0.0\n",
    "    try:\n",
    "        bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)[0]\n",
    "        feats['spectral_bandwidth_mean'] = float(np.mean(bw))\n",
    "        feats['spectral_bandwidth_std'] = float(np.std(bw))\n",
    "    except Exception:\n",
    "        feats['spectral_bandwidth_mean'] = 0.0\n",
    "        feats['spectral_bandwidth_std'] = 0.0\n",
    "    # MFCCs + deltas + delta2 (means and stds)\n",
    "    try:\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "        mfcc_delta = librosa.feature.delta(mfcc)\n",
    "        mfcc_delta2 = librosa.feature.delta(mfcc, order=2)\n",
    "        for i in range(mfcc.shape[0]):\n",
    "            feats[f'mfcc_{i}_mean'] = float(np.mean(mfcc[i]))\n",
    "            feats[f'mfcc_{i}_std'] = float(np.std(mfcc[i]))\n",
    "            feats[f'mfcc_delta_{i}_mean'] = float(np.mean(mfcc_delta[i]))\n",
    "            feats[f'mfcc_delta_{i}_std'] = float(np.std(mfcc_delta[i]))\n",
    "            feats[f'mfcc_delta2_{i}_mean'] = float(np.mean(mfcc_delta2[i]))\n",
    "            feats[f'mfcc_delta2_{i}_std'] = float(np.std(mfcc_delta2[i]))\n",
    "    except Exception:\n",
    "        for i in range(13):\n",
    "            feats[f'mfcc_{i}_mean'] = 0.0\n",
    "            feats[f'mfcc_{i}_std'] = 0.0\n",
    "            feats[f'mfcc_delta_{i}_mean'] = 0.0\n",
    "            feats[f'mfcc_delta_{i}_std'] = 0.0\n",
    "            feats[f'mfcc_delta2_{i}_mean'] = 0.0\n",
    "            feats[f'mfcc_delta2_{i}_std'] = 0.0\n",
    "    # Chroma (mean/std per bin)\n",
    "    try:\n",
    "        chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "        for i in range(chroma.shape[0]):\n",
    "            feats[f'chroma_{i}_mean'] = float(np.mean(chroma[i]))\n",
    "            feats[f'chroma_{i}_std'] = float(np.std(chroma[i]))\n",
    "    except Exception:\n",
    "        for i in range(12):\n",
    "            feats[f'chroma_{i}_mean'] = 0.0\n",
    "            feats[f'chroma_{i}_std'] = 0.0\n",
    "    # Spectral contrast (mean/std per band)\n",
    "    try:\n",
    "        contrast = librosa.feature.spectral_contrast(y=y, sr=sr)\n",
    "        for i in range(contrast.shape[0]):\n",
    "            feats[f'spectral_contrast_{i}_mean'] = float(np.mean(contrast[i]))\n",
    "            feats[f'spectral_contrast_{i}_std'] = float(np.std(contrast[i]))\n",
    "    except Exception:\n",
    "        for i in range(7):\n",
    "            feats[f'spectral_contrast_{i}_mean'] = 0.0\n",
    "            feats[f'spectral_contrast_{i}_std'] = 0.0\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8621c216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 audio files to process\n",
      "Extraction complete, rows: 0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "No feature rows were extracted. Check audio file locations.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 93\u001b[39m\n\u001b[32m     91\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mExtraction complete, rows:\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28mlen\u001b[39m(rows))\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(rows) == \u001b[32m0\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33mNo feature rows were extracted. Check audio file locations.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m     97\u001b[39m df = pd.DataFrame(rows)\n",
      "\u001b[31mRuntimeError\u001b[39m: No feature rows were extracted. Check audio file locations."
     ]
    }
   ],
   "source": [
    "# Discovery, extraction loop, and saving\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "def infer_person_phrase(p: Path):\n",
    "    \"\"\"Infer canonical person and phrase from a Path or filename.\n",
    "\n",
    "    Rules:\n",
    "    - Map any 'fidel' or 'fidele' occurrences to person 'Fidele'.\n",
    "    - Map 'kerie' -> 'Kerie', 'irais' -> 'Irais'.\n",
    "    - Map belyse variations like 'belyse', 'belise', 'belisee' to 'Belyse'.\n",
    "    - Phrase detection prefers keywords and returns one of:\n",
    "        'confirm_transaction' or 'yes_approve'.\n",
    "      When keywords aren't found the function falls back to a best-effort token.\n",
    "    - Ignore augmentation tokens like 'aug','noise','pitch','time','fast','slow','volume','up','down','stretch'.\n",
    "    \"\"\"\n",
    "    name = p.name.lower()\n",
    "    parts = [s.lower() for s in p.parts if s not in ('.', '')]\n",
    "\n",
    "    # Normalize person\n",
    "    person = 'unknown'\n",
    "    if any('kerie' in part for part in parts):\n",
    "        person = 'Kerie'\n",
    "    elif any('irais' in part for part in parts):\n",
    "        person = 'Irais'\n",
    "    elif any(('fidel' in part) or ('fidele' in part) for part in parts) or 'fidel' in name or 'fidele' in name:\n",
    "        person = 'Fidele'\n",
    "    elif any(k in name for k in ('belyse', 'belise', 'belisee')) or any(k in part for part in parts for k in ('belyse', 'belise', 'belisee')):\n",
    "        person = 'Belyse'\n",
    "\n",
    "    # Build tokens from stem, remove augmentation suffixes\n",
    "    aug_tokens = {'aug', 'augmented', 'noise', 'pitch', 'time', 'fast', 'slow', 'volume', 'up', 'down', 'stretch', 'orig', 'original'}\n",
    "    tokens = [t for t in re.split(r'[_\\-\\s]+', p.stem.lower()) if t]\n",
    "    tokens = [t for t in tokens if t not in aug_tokens]\n",
    "\n",
    "    # Phrase detection by keyword presence\n",
    "    phrase = p.stem.lower()\n",
    "    if any(k in name for k in ('confirm', 'transaction', 'confirm_tx', 'confirmtransaction')) or any(k in tok for tok in tokens for k in ('confirm', 'transaction', 'confirmtx', 'confirm_tx')):\n",
    "        phrase = 'confirm_transaction'\n",
    "    elif any(k in name for k in ('approve', 'yes', 'approve_yes', 'yes_approve')) or any(k in tok for tok in tokens for k in ('approve', 'yes')):\n",
    "        phrase = 'yes_approve'\n",
    "    else:\n",
    "        # fallback: try to pick a short token that is likely a phrase\n",
    "        candidates = [t for t in tokens if len(t) > 2 and t not in ('fidel','fidele','kerie','irais','belyse',)]\n",
    "        phrase = candidates[-1] if candidates else p.stem.lower()\n",
    "\n",
    "    return person, phrase\n",
    "\n",
    "# Prepare output directory\n",
    "out_dir = Path('features_audio')\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Candidate search roots (adjust if your audio lives elsewhere)\n",
    "search_roots = [Path('audio_data'), Path('augmented_audio'), Path('audio')]\n",
    "exts = {'.wav', '.flac', '.mp3', '.m4a', '.ogg'}\n",
    "files = []\n",
    "for root in search_roots:\n",
    "    if root.exists():\n",
    "        files += [p for p in root.rglob('*') if p.suffix.lower() in exts]\n",
    "# de-duplicate and sort\n",
    "files = sorted(set(files))\n",
    "print(f'Found {len(files)} audio files to process')\n",
    "\n",
    "rows = []\n",
    "seen = 0\n",
    "for f in files:\n",
    "    seen += 1\n",
    "    if seen % 50 == 0:\n",
    "        print('Processed', seen, 'files')\n",
    "    person, phrase = infer_person_phrase(f)\n",
    "    feats = extract_basic_features(str(f))\n",
    "    if feats is None:\n",
    "        continue\n",
    "    audio_id = f.stem\n",
    "    audio_name = f.name\n",
    "    audio_path = str(f)\n",
    "    augmentation = 'augmented' if any(s in audio_path.lower() for s in ('aug', 'augment', 'augmented')) else 'original'\n",
    "    is_augmented = augmentation != 'original'\n",
    "    row = {\n",
    "        'audio_id': audio_id,\n",
    "        'person': str(person),\n",
    "        'phrase': str(phrase),\n",
    "        'audio_name': audio_name,\n",
    "        'audio_path': audio_path,\n",
    "        'augmentation': augmentation,\n",
    "        'is_augmented': is_augmented,\n",
    "    }\n",
    "    row.update(feats)\n",
    "    rows.append(row)\n",
    "\n",
    "print('Extraction complete, rows:', len(rows))\n",
    "if len(rows) == 0:\n",
    "    raise RuntimeError('No feature rows were extracted. Check audio file locations.')\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "meta = ['audio_id','person','phrase','audio_name','audio_path','augmentation','is_augmented']\n",
    "feature_cols = [c for c in df.columns if c not in meta]\n",
    "# keep only numeric feature columns in the feature_columns file\n",
    "numeric_features = list(df[feature_cols].select_dtypes(include=[np.number]).columns)\n",
    "# save merged CSV and feature list\n",
    "out_csv = out_dir / 'audio_features.csv'\n",
    "df.to_csv(out_csv, index=False, encoding='utf-8')\n",
    "print('Saved merged features to', out_csv)\n",
    "with open(out_dir / 'feature_columns.txt', 'w', encoding='utf-8') as fh:\n",
    "    fh.write('\\n'.join(numeric_features))\n",
    "print('Saved feature column list to', out_dir / 'feature_columns.txt')\n",
    "print('Columns saved:', len(numeric_features))\n",
    "print(df.head().to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ba4c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root folder not found: C:\\Users\\LENOVO\\Documents\\KERIE\\ML_FORMATIVE2\\Formative-2-Data-Preprocessing\\notebooks\\augmented_audio\n",
      "\n",
      "No changes made to features_audio/audio_features.csv\n"
     ]
    }
   ],
   "source": [
    "# Append features for all subfolders under `augmented_audio`\n",
    "# This cell finds every person folder under `augmented_audio/`, extracts features\n",
    "# and appends only new unique rows to `features_audio/audio_features.csv`.\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def _safe_title_case(name):\n",
    "    # Convert folder like 'kerie' or 'Kerie_01' to 'Kerie' (single token, title-case)\n",
    "    s = str(name).replace('_', ' ').replace('-', ' ').strip()\n",
    "    if not s:\n",
    "        return s\n",
    "    tok = s.split()[0]\n",
    "    return tok.title()\n",
    "\n",
    "def append_features_from_augmented_root(root_dir='augmented_audio', out_csv_path=Path('features_audio/audio_features.csv')):\n",
    "    root = Path(root_dir)\n",
    "    exts = {'.wav', '.flac', '.mp3', '.m4a', '.ogg'}\n",
    "\n",
    "    if not root.exists():\n",
    "        print(f\"Root folder not found: {root.resolve()}\")\n",
    "        return None\n",
    "\n",
    "    # immediate subfolders are treated as person folders\n",
    "    subfolders = [d for d in sorted(root.iterdir()) if d.is_dir()]\n",
    "    if not subfolders:\n",
    "        print(f\"No subfolders found under {root}\")\n",
    "        return None\n",
    "\n",
    "    all_rows = []\n",
    "    summary = {}\n",
    "\n",
    "    for sub in subfolders:\n",
    "        files = [p for p in sub.rglob('*') if p.suffix.lower() in exts]\n",
    "        if not files:\n",
    "            summary[sub.name] = {'found': 0, 'processed': 0, 'skipped': 0}\n",
    "            print(f\"No audio files in {sub}\")\n",
    "            continue\n",
    "\n",
    "        processed = 0\n",
    "        skipped = 0\n",
    "        for f in files:\n",
    "            # infer person/phrase using existing helper if available\n",
    "            try:\n",
    "                person, phrase = infer_person_phrase(f)\n",
    "            except Exception:\n",
    "                person, phrase = ('unknown', f.stem.lower())\n",
    "\n",
    "            # If inference failed or doesn't match folder, force to folder name\n",
    "            if not person or person == 'unknown' or person.lower() not in sub.name.lower():\n",
    "                person = _safe_title_case(sub.name)\n",
    "\n",
    "            # Normalize phrase (use normalize_phrase if available)\n",
    "            try:\n",
    "                phrase = normalize_phrase(phrase)\n",
    "            except Exception:\n",
    "                phrase = str(phrase).lower().strip().replace(' ', '_')\n",
    "\n",
    "            feats = extract_basic_features(str(f))\n",
    "            if feats is None:\n",
    "                skipped += 1\n",
    "                continue\n",
    "\n",
    "            audio_id = f.stem\n",
    "            audio_name = f.name\n",
    "            audio_path = str(f)\n",
    "            augmentation = 'augmented' if any(tok in audio_path.lower() for tok in ('aug', 'augment', 'augmented')) else 'original'\n",
    "            is_augmented = augmentation != 'original'\n",
    "\n",
    "            row = {\n",
    "                'audio_id': audio_id,\n",
    "                'person': str(person),\n",
    "                'phrase': str(phrase),\n",
    "                'audio_name': audio_name,\n",
    "                'audio_path': audio_path,\n",
    "                'augmentation': augmentation,\n",
    "                'is_augmented': is_augmented,\n",
    "            }\n",
    "            row.update(feats)\n",
    "            all_rows.append(row)\n",
    "            processed += 1\n",
    "\n",
    "        summary[sub.name] = {'found': len(files), 'processed': processed, 'skipped': skipped}\n",
    "\n",
    "    if not all_rows:\n",
    "        print('No new feature rows extracted from any augmented subfolder.')\n",
    "        return None\n",
    "\n",
    "    new_df = pd.DataFrame(all_rows)\n",
    "\n",
    "    out_csv = Path(out_csv_path)\n",
    "    if out_csv.exists():\n",
    "        existing_df = pd.read_csv(out_csv)\n",
    "        existing_ids = set(existing_df['audio_id'].astype(str)) if 'audio_id' in existing_df.columns else set()\n",
    "        new_unique = new_df[~new_df['audio_id'].astype(str).isin(existing_ids)]\n",
    "        if new_unique.empty:\n",
    "            print('No new unique audio files to append (all audio_id already present).')\n",
    "            return existing_df\n",
    "        combined = pd.concat([existing_df, new_unique], ignore_index=True, sort=False)\n",
    "        appended_count = len(new_unique)\n",
    "    else:\n",
    "        combined = new_df\n",
    "        appended_count = len(new_df)\n",
    "\n",
    "    out_csv.parent.mkdir(parents=True, exist_ok=True)\n",
    "    combined.to_csv(out_csv, index=False)\n",
    "\n",
    "    print(f\"Appended {appended_count} rows to {out_csv}\")\n",
    "    print('Summary by folder:')\n",
    "    for k, v in summary.items():\n",
    "        print(f\"  {k}: found={v['found']} processed={v['processed']} skipped={v['skipped']}\")\n",
    "\n",
    "    return combined\n",
    "\n",
    "# Run the append for the augmented_audio root\n",
    "result_df = append_features_from_augmented_root('augmented_audio', out_csv_path=Path('features_audio/audio_features.csv'))\n",
    "if result_df is not None:\n",
    "    display_cols = [c for c in ['audio_id', 'person', 'phrase', 'audio_name', 'augmentation'] if c in result_df.columns]\n",
    "    print('\\nLast 10 rows (preview):')\n",
    "    print(result_df[display_cols].tail(10).to_string(index=False))\n",
    "else:\n",
    "    print('\\nNo changes made to features_audio/audio_features.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
